# 重复数据删除的分类

## 分类一&#x20;

***

重复数据删除根据应用的位置，可分为源端重复数据删除和目标端 重复数据删除两种，其中源端指备份数据的来源；目标端指备份系统。 所谓源端重复数据删除是指在源端判断数据重复的工作。例如，用户在 上传某数据的时候，可以操作以下步骤。

1. 使用单向函数（某些哈希算法）生成需要上传的数据的指纹 （Fingerprint）；
2. 把指纹发送到备份系统，等待确认；
3. 位于目标端的备份系统，判断是否存在相似的数据，给源端返 回数据是否存在的信息；
4. 源端接收信息后，决定是否上传数据。

源端重复数据删除的好处显而易见，如果数据已经被备份过了，则 不需要将数据再传送给备份系统。当然源端数据去重复，性能未必一定高，在确认数据交换的时候，需要传送大量的指纹（每块数据都会保留 一个“指纹”，为了保证指纹的唯一性可以使用比较好的哈希算法），这 是一笔不小的开销。

此外，如果源端是不可信的，则可能将引起某些安全问题。

试想以 下应用场景：假设一个备份系统中存有很多用户的工资信息，每个用户 都有一个工资单，且工资单的模板都是一样的，那么某些用户就可以去 探测其他人的工资信息，假设工资单中含有的信息是用户姓名、工号、 工资，如果用户A知道用户B的姓名、工号，想要猜测对方的工资，只要 在源端生成相关文件，然后上传给备份系统，一旦发现生成的文件没有 被上传，即可确定B的工资。虽然这种攻击是非常耗时的，但是在理论上 完全存在这种可能性。

和源端重复数据删除相对应的是**目标端重复数据删除**，在这种情况 下，源端只要把数据上传给位于目标端的备份系统即可，源端甚至感受 不到重复数据删除技术的存在。所有的数据都会通过网络或其他传输机 制交给备份系统，备份系统对接收的数据统一地应用重复数据删除技 术。相比源端重复数据删除，目标端重复数据删除虽然对传输数据的网 络带宽占据较大，但是也有很多好处：客户端完全透明，去除了安全方 面的隐患，也不用对客户端做维护工作，如版本升级；去重复数据都在 目标端，使得管理集中，可进行全局的去重复，可称为一个相对独立的 系统。



## 分类二

***

根据数据在备份系统中进行重复数据删除的时间发生点，分为离线 （Post-process）重复数据删除和在线（Inline）重复数据删除两种。

离线重复数据删除，是指在用户数据上传的过程中，数据去重复并 不会发生，直接写到存储设备上；当用户数据上传完全结束后，再进行 相关的数据去重复工作。

{% hint style="info" %}
如何理解？

这样的方式可以理解成那些有很多胃的食草动物（如牛），先把食物吃到胃中，然后在某个时间点再进行反刍，以完 全消化食物。有反刍能力的食草动物一般有多个胃，对应到备份系统 中，就是至少需要两个存储设备。
{% endhint %}

试想如下的场景：用户的备份数据是 1PB，备份系统需要的存储至少要大于1PB。其中第一个存储设备大小为 1PB，用于存储用户上传的数据，另外一个存储设备大小为X （X 为应用 重复数据删除后的数据大小，为0～1PB）。这样的去重复手段，相信读 者一定会看出其中的问题，即为了确保重复数据删除能正常进行，最差 的情况下会有100%的额外存储资源消耗。

为了解决这个问题，在线重复数据删除技术应运而生。所谓在线重 复数据删除，就是在用户数据通过网络上传到备份系统的时候，数据去 重复就会发生。用户的数据会被重复数据删除子系统分成不同的部分， 每个部分视为一个块（Chunk）或切片，每个数据切片会被计算一个相应 的指纹，然后通过指纹去查找相关数据切片是否存在，一旦存在，这个 数据切片就不会被写入真实的存储设备中。但这一过程对CPU和内存的 消耗是非常高的。

虽然存储某个数据需要先查找数据切片是否存在，但是如果能找到 这个数据切片，则避免了大量外部存储写操作，以及过多的存储（磁盘 I/O）的操作时间，反而提高了备份的速度。另外，多次备份的内容存在 很大的相似性，这带来的好处是非常可观的，因此，在线重复数据删除 同时“压榨”CPU、内存、网络、存储I/O等模块，使得整个系统的资源能 被更好地利用，与离线重复数据删除相比是一个不小的进步。

当然重复数据删除还有很多其他分类，如根据目标端的备份系统可 分为单机重复数据删除或分布式重复数据删除

